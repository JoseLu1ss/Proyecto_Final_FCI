{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTACIÓN DE LIBRERÍAS\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from string import ascii_uppercase as alfabeto\n",
    "import pickle\n",
    "\n",
    "\n",
    "#Para el WebScraping\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "#Para las predicciones en el modelo\n",
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA COLLECTION**\n",
    "\n",
    "En esta parte del notebook nos encargamos de acceder a los datos con la clase DataGetter, de allí obtenemos los datos en la tabla_ca. Luego lo exportamos a un archivo de pickle. Este archivo, llamado tabla_ca contiene las cuatro tablas de posiciones de la fase de grupos de la Copa América 2024. Posteriormente, con la clase DataCollector obtenemos los datos históricos de los partidos de la Copa América, por un lado usando WebScraping con bs4 y BeautifulSoup, por el otro accediendo al driver de Chrome usando selenium y realizando nuevamente WebScraping. Luego, exportamos los datos en tres archivos .csv que servirán posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGetter:\n",
    "    '''\n",
    "    Clase encargada de obtener los partidos de la Copa America 2024 y el Ranking Mundial de la FIFA actual.\n",
    "    \n",
    "    Atributos:\n",
    "        url: path de la página Web.\n",
    "\n",
    "    Métodos:\n",
    "        charger: Se encarga de leer el path y entregar una lista tratable con pandas.\n",
    "        organicer: Se encargada de organizar, filtrar y dejar listos los datos cargados. \n",
    "    '''\n",
    "    def __init__(self, url):\n",
    "        self.link = url #Link de la página web a la que accedemos\n",
    "    \n",
    "    def charger(self):\n",
    "        '''\n",
    "        Lee la página web y devuelve los datos en forma de lista.\n",
    "\n",
    "        Retorna:\n",
    "            data (list): Lista de DataFrames leídos de la página web.\n",
    "        '''\n",
    "        \n",
    "        data = pd.read_html(self.link) #Leemos la página web\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def organicer(self, data):\n",
    "        '''\n",
    "        Organiza los datos en tablas por grupos.\n",
    "\n",
    "        Parámetros:\n",
    "            data (list): Lista de DataFrames a organizar.\n",
    "\n",
    "        Retorna:\n",
    "            dict_tables (dict): Diccionario con los datos organizados por grupos.\n",
    "        '''\n",
    "        \n",
    "        dict_tables = {} #Creamos un diccionario vacío para rellenarlo con las tablas\n",
    "        for letra, i in zip(alfabeto, range(14, 42, 7)): #Según el patrón encontrado, iteramos\n",
    "            df = data[i] #Definimos el DataFrame para cada elemento encontrado en la web\n",
    "            df.rename(columns={df.columns[1]: 'Team'}, inplace=True)\n",
    "            df.pop('Qualification') #Borramos columnas innecesarias\n",
    "            dict_tables[f'Group {letra}'] = df #Definimos el nombre de cada grupo (A, B, C, D)\n",
    "            \n",
    "        for group in dict_tables:\n",
    "            dict_tables[group]['Pts'] = 0\n",
    "\n",
    "            #Renombramos algunas selecciones que presentaron problemas\n",
    "            dict_tables['Group C'].loc[2, 'Team'] = 'United States'\n",
    "            dict_tables['Group D'].loc[0, 'Team'] = 'Colombia'\n",
    "            dict_tables['Group D'].loc[3, 'Team'] = 'Paraguay'\n",
    "            \n",
    "        return dict_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Links con la info de la Copa América 2024 y el Ranking Mundial de la FIFA\n",
    "url_ca = 'https://en.wikipedia.org/wiki/2024_Copa_America'\n",
    "\n",
    "#Creamos los objetos que nos permiten extraer la data de los links correspondientes\n",
    "Copa_America = DataGetter(url_ca)\n",
    "\n",
    "#Leemos los datos de la web\n",
    "datos_ca = Copa_America.charger()\n",
    "\n",
    "#Organizamos y presentamos los datos previamente cargados\n",
    "tabla_ca = Copa_America.organicer(datos_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos los datos de las tablas de la Copa América 2024\n",
    "with open('tabla_ca', 'wb') as output:\n",
    "    pickle.dump(tabla_ca, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollector:\n",
    "\n",
    "    '''\n",
    "    Clase diseñada para recolectar los datos de los partidos de cada edición de la Copa America \n",
    "    (datos históricos)\n",
    "\n",
    "    Métodos: \n",
    "        \n",
    "        - get_matches: Se encarga de utilizar WebScraping con bs4 para obtener los datos de los partidos\n",
    "        de la Copa América en una edición específica.\n",
    "\n",
    "        - getTotalMatches: Se encarga de recolectar todos los datos históricos de los partidos de la\n",
    "        Copa América (todas las ediciones).\n",
    "\n",
    "        -getMissingMatches: Se encarga de utilizar WebScraping con Selenium para obtener los datos faltantes,\n",
    "        que no pudieron ser recolectados con bs4.\n",
    "\n",
    "        -getTotalMissingMatches: Se encarga de recolectar los datos faltantes de todas las ediciones que no \n",
    "        pudieron ser obtenidas con bs4 (en este caso, eidiciones 2011 y 2015).\n",
    "\n",
    "        \n",
    "    '''\n",
    " \n",
    "    def getMatches(self, year):\n",
    "        \n",
    "        '''\n",
    "        Extrae los partidos de una página web usando técnicas de WebScraping.\n",
    "        \n",
    "        Parámetros:\n",
    "            year (int): Año de la edición de Copa América.\n",
    "\n",
    "        Retorna:\n",
    "            df_America (pd.DataFrame): Data con los partidos extraídos de la página web.\n",
    "        '''\n",
    "\n",
    "        \n",
    "        if year <= 1967:\n",
    "            urls = f'https://en.wikipedia.org/wiki/{year}_South_American_Championship'\n",
    "            \n",
    "        else:\n",
    "            urls = f'https://en.wikipedia.org/wiki/{year}_Copa_America'\n",
    "            \n",
    "        response = requests.get(urls) #Realizamos la solicitud de acceso a la web\n",
    "        content = response.text #Extraemos el contenido en forma de texto\n",
    "        \n",
    "        soup = BeautifulSoup(content, 'lxml') #Damos acceso al scraping\n",
    "        matches = soup.find_all('div', class_=\"footballbox\") #Filtramos los datos que buscamos\n",
    "\n",
    "        #Creamos tres listas vacías, para construir un diccionario\n",
    "        home = []\n",
    "        score = []\n",
    "        away = []\n",
    "        \n",
    "        #Un ciclo for para cada elemento que cumpla la condición de filtrado y sea añadido a la lista matches\n",
    "        for match in matches:\n",
    "            #Llenamos las tres listas de acuerdo a la clase adecuada en el html de la web\n",
    "            home.append(match.find('th', class_=\"fhome\").get_text()) #Llenamos el home\n",
    "            score.append(match.find('th', class_=\"fscore\").get_text()) #Llenamos el score\n",
    "            away.append(match.find('th', class_=\"faway\").get_text()) #Llenamos el away\n",
    "            \n",
    "        dict_America = {'home':home, \n",
    "                        'score':score,\n",
    "                        'away':away}\n",
    "\n",
    "        #Creamos un DataFrame con los datos extraídos y con una columna adicional del año\n",
    "        df_America = pd.DataFrame(dict_America)\n",
    "        df_America['year'] = year\n",
    "\n",
    "        return df_America\n",
    "    \n",
    "    def getTotalMatches(self, years):\n",
    "        \n",
    "        #Llenamos una lista con el total de partidos en todas las ediciones de la Copa América\n",
    "        TotalMatches = [self.getMatches(year) for year in years]\n",
    "        df_TotalMatches = pd.concat(TotalMatches, ignore_index=True) #Creamos el DF concatenando todos los partidos\n",
    "\n",
    "        #DataFrame que almacena el histórico de partidos de la Copa América\n",
    "        df_conmebol = df_TotalMatches[df_TotalMatches['year'] != 2024]\n",
    "        #DataFrame que almacena el total de partidos de la edición 2024 (el fixture del torneo)\n",
    "        df_fixture = df_TotalMatches[df_TotalMatches['year'] == 2024]\n",
    "\n",
    "        return df_conmebol, df_fixture\n",
    "    \n",
    "    def getMissingMatches(self, year):\n",
    "        service = Service(ChromeDriverManager().install()) #Instalamos (inicializamos) el Driver de Chrome\n",
    "        driver = webdriver.Chrome(service=service) #Creamos el controlador (driver)\n",
    "        \n",
    "        url = f'https://en.wikipedia.org/wiki/{year}_Copa_America' #Link de la web\n",
    "        \n",
    "        driver.get(url) #Habilitamos el acceso al driver \n",
    "        \n",
    "        #Indicamos al driver qué elementos extraer de la página web \n",
    "        missing_matches = driver.find_elements(by='xpath', value='//tr[@style=\"font-size:90%\"]')\n",
    "\n",
    "        #A partir de aquí, realizamos un procedimiento similar al de getMatches()\n",
    "        home = []\n",
    "        score = []\n",
    "        away = []\n",
    "\n",
    "        for match in missing_matches:\n",
    "            home.append(match.find_element(by='xpath', value='./td[1]').text)\n",
    "            score.append(match.find_element(by='xpath', value='./td[2]').text)\n",
    "            away.append(match.find_element(by='xpath', value='./td[3]').text)\n",
    "\n",
    "        dict_missing = {'home':home, \n",
    "                    'score':score,\n",
    "                    'away':away}\n",
    "\n",
    "        df_missing = pd.DataFrame(dict_missing)\n",
    "        df_missing['year'] = year\n",
    "        time.sleep(1) #Tiempo de espera para pasar de una página a la otra\n",
    "\n",
    "        return df_missing\n",
    "    \n",
    "    def getTotalMissingMatches(self, years):\n",
    "        #Todo similar a getTotalMatches\n",
    "        missing_data = [self.getMissingMatches(year) for year in years]\n",
    "        df_missing_data = pd.concat(missing_data, ignore_index=True)\n",
    "\n",
    "        return df_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Años de cada edición realizada por la Copa América\n",
    "years_America = [1916, 1917, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1929, 1935, 1937, 1939, 1941,\n",
    "                 1942, 1945, 1946, 1947, 1949, 1953, 1955, 1956, 1957, 1963, 1967, 1975, 1979, 1983, 1987, 1989,\n",
    "                 1991, 1993, 1995, 1997, 1999, 2001, 2004, 2007, 2011, 2015, 2016, 2019, 2021, 2024]\n",
    "\n",
    "missing_years = [2011, 2015]\n",
    "\n",
    "\n",
    "Partidos = DataCollector() #Creamos el objeto que nos permitirá acceder a los datos históricos de los partidos\n",
    "tablas = Partidos.getTotalMatches(years_America) #Datos con total de partidos obtenidos con bs4\n",
    "tablas_perdidas = Partidos.getTotalMissingMatches(missing_years) #Datos con total de partidos obtenidos con Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos a archivos .csv los datos recolectados anteriormente\n",
    "tablas[0].to_csv('Conmebol_Copa_America_initial_data.csv', index=False)\n",
    "tablas[1].to_csv('Programacion_Copa_America_2024.csv', index=False)\n",
    "tablas_perdidas.to_csv('Conmebol_Copa_America_missing_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA CLEAN**\n",
    "\n",
    "En esta parte del notebook nos encargamos de limpiar los datos. Con la clase DataCleanner, leemos los datos de los partidos totales históricos y del fixture de la Copa América 2024, además calculamos la fuerza de cada equipo de la copa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "    '''\n",
    "    Clase encargada de limpiar los datos obtenidos usando WebScraping.\n",
    "    \n",
    "    Atributos:\n",
    "        - archivei con i = 1, 2, 3: Son los path de los archivos .csv con los datos necesarios\n",
    "        \n",
    "    Métodos:\n",
    "        - readData: Se encarga de convertir los archivos .csv en un DataFrame de pandas.\n",
    "\n",
    "        - cleanData: Se encarga de limpiar y transformar los datos para el uso adecuado.\n",
    "    '''\n",
    "    def __init__(self, archive1, archive2, archive3):\n",
    "        \n",
    "        #Cargamos los tres archivos a limpiar\n",
    "        self.path1 = archive1\n",
    "        self.path2 = archive2\n",
    "        self.path3 = archive3\n",
    "    \n",
    "    def readData(self):\n",
    "        \n",
    "        #Leemos los tres archivos\n",
    "        data1 = pd.read_csv(self.path1)\n",
    "        data2 = pd.read_csv(self.path2)\n",
    "        data3 = pd.read_csv(self.path3)\n",
    "        \n",
    "        return data1, data2, data3\n",
    "    \n",
    "    def cleanData(self, data, mode = 'fixture'):\n",
    "        if mode == 'fixture': #Limpieza del Fixture de la Copa actual\n",
    "            #Corregimos los espacios en blanco\n",
    "            data[0]['home'] = data[0].home.str.strip()\n",
    "            data[0]['away'] = data[0].away.str.strip()\n",
    "\n",
    "            #Debido a que la página de Wikipedia ha sido actualizada, debemos editar el fixture\n",
    "            for i in range(32):\n",
    "                data[0].loc[i, 'score'] = f'Match {i+1}'\n",
    "\n",
    "                data[0].loc[24, 'home'] = 'Winner Group A'\n",
    "                data[0].loc[24, 'away'] = 'Runner-up Group B'\n",
    "                data[0].loc[25, 'home'] = 'Winner Group B'\n",
    "                data[0].loc[25, 'away'] = 'Runner-up Group A'\n",
    "                data[0].loc[26, 'home'] = 'Winner Group D'\n",
    "                data[0].loc[26, 'away'] = 'Runner-up Group C'\n",
    "                data[0].loc[27, 'home'] = 'Winner Group C'\n",
    "                data[0].loc[27, 'away'] = 'Runner-up Group D'\n",
    "                \n",
    "                data[0].loc[28, 'home'] = 'Winner Match 25'\n",
    "                data[0].loc[28, 'away'] = 'Winner Match 26'\n",
    "                data[0].loc[29, 'home'] = 'Winner Match 27'\n",
    "                data[0].loc[29, 'away'] = 'Winner Match 28'\n",
    "\n",
    "                data[0].loc[30, 'home'] = 'Loser Match 29'\n",
    "                data[0].loc[30, 'away'] = 'Loser Match 30'\n",
    "\n",
    "                data[0].loc[31, 'home'] = 'Winner Match 29'\n",
    "                data[0].loc[31, 'away'] = 'Winner Match 30'\n",
    "\n",
    "            return data[0] #Retornamos la data del fixture limpia\n",
    "        \n",
    "        elif mode == 'data': #Limpieza de los datos históricos\n",
    "            #Unimos los datos recolectados con ambas herramientas de WebScraping\n",
    "            df_complete_data = pd.concat([data[1], data[2]], ignore_index=True)\n",
    "            df_complete_data.drop_duplicates(inplace=True) #Eliminamos todos los posibles duplicados\n",
    "            df_complete_data.sort_values('year', inplace=True) #Organizamos los datos en orden ascendente\n",
    "\n",
    "            df_complete_data['score'] = df_complete_data['score'].str.strip() #Borramos espacios en blanco\n",
    "            df_complete_data['score'] = df_complete_data['score'].str.replace('[^\\d–]', '', regex=True)\n",
    "            \n",
    "            #Borramos espacios en blanco de los valores de local y visitante\n",
    "            df_complete_data['home'] = df_complete_data.home.str.strip()\n",
    "            df_complete_data['away'] = df_complete_data.away.str.strip()\n",
    "\n",
    "            df_complete_data[['home_goals', 'away_goals']] = df_complete_data['score'].str.split('–', expand=True)\n",
    "            df_complete_data.drop('score', axis=1, inplace=True)\n",
    "\n",
    "            #Asignamos los valores de los goles como tipo entero\n",
    "            df_complete_data = df_complete_data.astype({'home_goals': int, 'away_goals':int, 'year':int})\n",
    "\n",
    "            #Separamos en dos DataFrame para el local y el visitante respectivamente\n",
    "            df_home =  df_complete_data[['home', 'home_goals', 'away_goals']]\n",
    "            df_away =  df_complete_data[['away', 'home_goals', 'away_goals']]\n",
    "\n",
    "            #Renombramos las columnas para cada DataFrame creado\n",
    "            df_home = df_home.rename(columns={'home':'Team', 'home_goals':'Goals_Scored', 'away_goals':'Goals_Conceded'})\n",
    "            df_away = df_away.rename(columns={'away':'Team', 'home_goals':'Goals_Conceded', 'away_goals':'Goals_Scored'}) \n",
    "\n",
    "            #Retornamos la data limpia de los partidos históricos, y también separado en local/visitante\n",
    "            return df_complete_data, df_home, df_away\n",
    "        \n",
    "    def teamStrength(self, df_h, df_a):\n",
    "        #La fuerza del equipo está relacionada con el promedio histórico de goles anotados y recibidos\n",
    "        df_team_strength = pd.concat([df_h, df_a], ignore_index=True).groupby('Team').mean()\n",
    "        return df_team_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos el objeto que nos permite limpiar la data\n",
    "Tablas = DataCleaner('Programacion_Copa_America_2024.csv',\n",
    "                    'Conmebol_Copa_America_initial_data.csv',\n",
    "                    'Conmebol_Copa_America_missing_data.csv')\n",
    "\n",
    "data = Tablas.readData() #Leemos la data\n",
    "df_fixture = Tablas.cleanData(data) #Obtenemos los datos limpios del Fixture de la Copa América 2024\n",
    "df_data = Tablas.cleanData(data, 'data') #Obtenemos los datos limpios de los partidos históricos de la copa\n",
    "df_complete_data = df_data[0] #Los datos históricos completos\n",
    "#Los datos históricos limpios, separados en local y visitante\n",
    "df_home = df_data[1]\n",
    "df_away = df_data[2]\n",
    "df_strength = Tablas.teamStrength(df_home, df_away)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODELING**\n",
    "\n",
    "En esta parte del notebook nos encargamos de desarrollar el modelo que simulará el torneo y predecirá el campeón de la competencia. Usamos la clase Modeling, la cual se encarga de desarrollar todos los pasos necesarios para la simulación del torneo y la predicción del ganador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modeling:\n",
    "    '''\n",
    "    Clase encargada de realizar la simulación del torneo, desde la fase de grupos hasta las fases eliminatorias\n",
    "    (Cuartos de final, Semifinal) y la final. Basando la simulación en una conocida función densidad de\n",
    "    probabilidad.\n",
    "\n",
    "    Atributos:\n",
    "        - tablas: Conjunto de DataFrames con las tablas de posiciones de los grupos de la Copa.\n",
    "\n",
    "        - fuerza: DataFrame con la información de la fuerza de los equipos.\n",
    "\n",
    "    Métodos:\n",
    "        - teamStrength: Se encarga de presentar la fuerza de cada equipo de la Copa.\n",
    "        \n",
    "        - Rounds: Se encarga de separar el fixture en las diferentes fases del torneo.\n",
    "\n",
    "        - predictPoints: Se encarga de realizar la predicción de los puntos de los equipos.\n",
    "\n",
    "        - getWinner: Se encarga de asignar al ganador de los partidos en cada fase. \n",
    "        \n",
    "        - uptadeTable: Se encarga de actualizar las tablas, una vez actualizadas las rondas\n",
    "\n",
    "        - simulateTournament: Se encarga de simular la fase de grupos, y simular las diferentes fases del torneo\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, tabla, df_s):\n",
    "        self.tablas = tabla\n",
    "        self.fuerza = df_s\n",
    "    \n",
    "    def Rounds(self, df_f):\n",
    "        #Separamos el fixture en las diferentes fases del torneo\n",
    "        df_groups = df_f[:24].copy() #Fase de grupos\n",
    "        df_fixture_quarter = df_f[24:28].copy() #Cuartos de Final \n",
    "        df_fixture_semi = df_f[28:30].copy() #Semifinal \n",
    "        df_fixture_final = df_f[31:].copy() #Final\n",
    "\n",
    "        return [df_groups, df_fixture_quarter, df_fixture_semi, df_fixture_final]\n",
    "\n",
    "    def predictPoints(self, home, away):\n",
    "        if home in self.fuerza.index and away in self.fuerza.index:\n",
    "            #goals_scored*goals_conceded\n",
    "            #Creamos los parámetros lambda para la distribución de probabilidad de home/away\n",
    "            lamb_home = self.fuerza.at[home, 'Goals_Scored'] * self.fuerza.at[away, 'Goals_Conceded']\n",
    "            lamb_away = self.fuerza.at[away, 'Goals_Scored'] * self.fuerza.at[home, 'Goals_Conceded']\n",
    "            #Inicializamos la probabilidad de victoria, empate y derrota en cero\n",
    "            prob_home, prob_away, prob_draw = 0, 0, 0\n",
    "\n",
    "            for i in range(7): #Goles equipo local\n",
    "                for j in range(7): #Goles equipo visitante\n",
    "                    #Obtenemos la probabilidad de que el equipo local marque i goles y el visitante j goles\n",
    "                    p = poisson.pmf(i, lamb_home) * poisson.pmf(j, lamb_away)\n",
    "                    \n",
    "                    #En casos de empate \n",
    "                    if i == j:\n",
    "                        prob_draw += p\n",
    "                    #En casos de que gane el local\n",
    "                    elif i > j:\n",
    "                        prob_home += p\n",
    "                    #En casos de que gane el visitante\n",
    "                    else:\n",
    "                        prob_away += p\n",
    "        \n",
    "            #Retornamos la predicción de puntos para el local y el visitante\n",
    "            points_home = 3 * prob_home + prob_draw\n",
    "            points_away = 3 * prob_away + prob_draw\n",
    "\n",
    "            return (points_home, points_away)\n",
    "        else:\n",
    "            return (0,0)\n",
    "        \n",
    "    def getWinner(self, df_updated):\n",
    "        for index, row in df_updated.iterrows():\n",
    "            home, away = row['home'], row['away']\n",
    "            points_home, points_away = self.predictPoints(home, away)\n",
    "            if points_home > points_away:\n",
    "                winner = home\n",
    "            else:\n",
    "                winner = away\n",
    "                \n",
    "            df_updated.loc[index, 'Winner'] = winner\n",
    "        return df_updated\n",
    "    \n",
    "    def uptadeTable(self, df_fixture_1, df_fixture_2):\n",
    "        for index, row in df_fixture_1.iterrows():\n",
    "            winner = df_fixture_1.loc[index, 'Winner']\n",
    "            match = df_fixture_1.loc[index, 'score']\n",
    "            df_fixture_2.replace({f'Winner {match}':winner}, inplace=True)\n",
    "            \n",
    "        df_fixture_2['Winner'] = ''\n",
    "        return df_fixture_2\n",
    "    \n",
    "        \n",
    "    def simulateTournament(self, df):#[df_groups, df[1], df[2] df[3]]):\n",
    "        #Creamos un ciclo for que recorra cada grupo de la Copa América en las tablas\n",
    "        for group in self.tablas:\n",
    "            teams_in_group = self.tablas[group]['Team'].values #Extraemos los equipos de cada grupo\n",
    "            #Filtramos los 6 partidos jugados por cada grupo \n",
    "            df_fixture_real_matches = df[0][df[0]['home'].isin(teams_in_group)] \n",
    "                \n",
    "            #Creamos un ciclo for que se itera en cada fila de los 6 partidos de cada grupo \n",
    "            for index, row in df_fixture_real_matches.iterrows():\n",
    "                home, away = row['home'], row['away'] #Extraemos el equipo local y visitante\n",
    "                #Asignamos los puntos a cada equipo en todos los grupos de la copa\n",
    "                points_home, points_away = self.predictPoints(home, away)\n",
    "                #Actualizamos las tablas de cada grupo, con los puntos obtenidos por equipo\n",
    "                self.tablas[group].loc[self.tablas[group]['Team'] == home, 'Pts'] += points_home\n",
    "                self.tablas[group].loc[self.tablas[group]['Team'] == away, 'Pts'] += points_away \n",
    "        \n",
    "            self.tablas[group] = self.tablas[group].sort_values('Pts', ascending=False).reset_index() \n",
    "            self.tablas[group] = self.tablas[group][['Team', 'Pts']]\n",
    "            self.tablas[group] = self.tablas[group].round(0)\n",
    "\n",
    "            group_winner = self.tablas[group].loc[0, 'Team']\n",
    "            group_runner_up = self.tablas[group].loc[1, 'Team']\n",
    "\n",
    "            df[1].replace({f'Winner {group}': group_winner,\n",
    "                           f'Runner-up {group}': group_runner_up}, \n",
    "                           inplace=True)\n",
    "        \n",
    "        df[1]['Winner'] = ''\n",
    "\n",
    "        df[1] = self.getWinner(df[1])\n",
    "    \n",
    "\n",
    "        df[2]= self.uptadeTable(df[1], df[2])\n",
    "        df[2] = self.getWinner(df[2])\n",
    "\n",
    "        df[3] = self.uptadeTable(df[2], df[3])\n",
    "        df[3] = self.getWinner(df[3])\n",
    "\n",
    "        df_complete = pd.concat([df[1], df[2], df[3]], ignore_index=True)\n",
    "\n",
    "        return df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simulator = Modeling(tabla_ca, df_strength)\n",
    "tournament = Simulator.Rounds(df_fixture)\n",
    "final = Simulator.simulateTournament(tournament)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['Fase'] = ''\n",
    "for i in range(4):\n",
    "    final.loc[i, 'Fase'] = 'Cuartos de Final'\n",
    "final.loc[4, 'Fase'] = 'Semi-Final'\n",
    "final.loc[5, 'Fase'] = 'Semi-Final'\n",
    "final.loc[6, 'Fase'] = 'Final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>score</th>\n",
       "      <th>away</th>\n",
       "      <th>year</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Fase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Match 25</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>2024</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Cuartos de Final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>Match 26</td>\n",
       "      <td>Peru</td>\n",
       "      <td>2024</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Cuartos de Final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>Match 27</td>\n",
       "      <td>United States</td>\n",
       "      <td>2024</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Cuartos de Final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uruguay</td>\n",
       "      <td>Match 28</td>\n",
       "      <td>Paraguay</td>\n",
       "      <td>2024</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>Cuartos de Final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Match 29</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2024</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Semi-Final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>Match 30</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>2024</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Semi-Final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Match 32</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2024</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Final</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        home     score           away  year     Winner              Fase\n",
       "0  Argentina  Match 25        Ecuador  2024  Argentina  Cuartos de Final\n",
       "1     Mexico  Match 26           Peru  2024     Mexico  Cuartos de Final\n",
       "2     Brazil  Match 27  United States  2024     Brazil  Cuartos de Final\n",
       "3    Uruguay  Match 28       Paraguay  2024    Uruguay  Cuartos de Final\n",
       "4  Argentina  Match 29         Mexico  2024  Argentina        Semi-Final\n",
       "5     Brazil  Match 30        Uruguay  2024     Brazil        Semi-Final\n",
       "6  Argentina  Match 32         Brazil  2024  Argentina             Final"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
