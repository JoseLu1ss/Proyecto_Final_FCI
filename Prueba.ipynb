{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTACIÓN DE LIBRERÍAS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import ascii_uppercase as alfabeto\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGetter:\n",
    "    '''\n",
    "    Clase encargada de obtener los partidos de la Copa America 2024 y el Ranking Mundial de la FIFA actual.\n",
    "    \n",
    "    Atributos:\n",
    "        url: path de la página Web.\n",
    "\n",
    "    Métodos:\n",
    "        charger: Se encarga de leer el path y entregar una lista tratable con pandas.\n",
    "        organicer: Se encargada de organizar, filtrar y dejar listos los datos cargados. \n",
    "    '''\n",
    "    def __init__(self, url):\n",
    "        self.link = url #Link de la página web a la que accedemos\n",
    "    \n",
    "    def charger(self):\n",
    "        data = pd.read_html(self.link) #Leemos la página web\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def organicer(self, data, mode = 'CA'):\n",
    "        if mode == 'CA': #Si mode = CA indica que organizamos los datos de las tablas de la Copa América\n",
    "            dict_tables = {} #Creamos un diccionario vacío para rellenarlo con las tablas\n",
    "            for letra, i in zip(alfabeto, range(14, 42, 7)): #Según el patrón encontrado, iteramos\n",
    "                df = data[i] #Definimos el DataFrame para cada elemento encontrado en la web\n",
    "                df.rename(columns={df.columns[1]: 'Team'}, inplace=True)\n",
    "                df.pop('Qualification') #Borramos columnas innecesarias\n",
    "                dict_tables[f'Group {letra}'] = df #Definimos el nombre de cada grupo (A, B, C, D)\n",
    "            \n",
    "            for group in dict_tables:\n",
    "                dict_tables[group]['Pts'] = 0\n",
    "\n",
    "            #Renombramos algunas selecciones que presentaron problemas\n",
    "            dict_tables['Group C'].loc[2, 'Team'] = 'United States'\n",
    "            dict_tables['Group D'].loc[0, 'Team'] = 'Colombia'\n",
    "            dict_tables['Group D'].loc[3, 'Team'] = 'Paraguay'\n",
    "\n",
    "            \n",
    "            return dict_tables\n",
    "        \n",
    "        elif mode == 'RM': #Si mode = RM indica que organizamos los datos del ranking mundial de selecciones\n",
    "            \n",
    "            #Definimos los DataFrame de los ranking de acuerdo al patrón encontrado en la lectura de la Web\n",
    "            historical_ranking = data[3]\n",
    "            actual_ranking = data[0]\n",
    "\n",
    "            #Leyendo los datos, analizamos columnas innecesarias que deben ser eliminadas\n",
    "            actual_ranking = actual_ranking.drop(0)\n",
    "            actual_ranking = actual_ranking.drop(1)\n",
    "            actual_ranking = actual_ranking.drop(2)\n",
    "            actual_ranking = actual_ranking.drop(23)\n",
    "            actual_ranking = actual_ranking.drop(24)\n",
    "\n",
    "            #Renombramos las columnas para que tengan nombres adecuados\n",
    "            actual_ranking.rename(columns={actual_ranking.columns[0]: 'Rank'}, inplace=True)\n",
    "            actual_ranking.rename(columns={actual_ranking.columns[1]: 'Change'}, inplace=True)\n",
    "            actual_ranking.rename(columns={actual_ranking.columns[2]: 'Team'}, inplace=True)\n",
    "            actual_ranking.rename(columns={actual_ranking.columns[3]: 'Points'}, inplace=True)\n",
    "\n",
    "            actual_ranking.pop('Change') #Eliminamos la columna que nos da info irrelevante\n",
    "\n",
    "            return actual_ranking, historical_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Links con la info necesaria\n",
    "url_ca = 'https://en.wikipedia.org/wiki/2024_Copa_America'\n",
    "url_rm = \"https://en.wikipedia.org/wiki/FIFA_Men's_World_Ranking\"\n",
    "\n",
    "#Creamos los objetos correspondientes\n",
    "Copa_America = DataGetter(url_ca)\n",
    "Ranking_Mundial = DataGetter(url_rm)\n",
    "\n",
    "#Cargamos los datos\n",
    "datos_ca = Copa_America.charger()\n",
    "datos_rm = Ranking_Mundial.charger()\n",
    "\n",
    "#Organizamos y presentamos los datos\n",
    "tabla_ca = Copa_America.organicer(datos_ca)\n",
    "tabla_rm = Ranking_Mundial.organicer(datos_rm, mode = 'RM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tabla_ca', 'wb') as output:\n",
    "    pickle.dump(tabla_ca, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollector:\n",
    "\n",
    "    '''\n",
    "    Clase diseñada para recolectar los datos de los partidos de cada edición de la Copa America \n",
    "    (datos históricos)\n",
    "\n",
    "    Métodos: \n",
    "        \n",
    "        - get_matches: Se encarga de utilizar WebScraping con bs4 para obtener los datos de los partidos\n",
    "        de la Copa América en una edición específica.\n",
    "\n",
    "        - getTotalMatches: Se encarga de recolectar todos los datos históricos de los partidos de la\n",
    "        Copa América (todas las ediciones).\n",
    "\n",
    "        -getMissingMatches: Se encarga de utilizar WebScraping con Selenium para obtener los datos faltantes,\n",
    "        que no pudieron ser recolectados con bs4.\n",
    "\n",
    "        -getTotalMissingMatches: Se encarga de recolectar los datos faltantes de todas las ediciones que no \n",
    "        pudieron ser obtenidas con bs4 (en este caso, eidiciones 2011 y 2015).\n",
    "\n",
    "        \n",
    "    '''\n",
    " \n",
    "    def get_matches(self, year):\n",
    "        \n",
    "        if year <= 1967:\n",
    "            urls = f'https://en.wikipedia.org/wiki/{year}_South_American_Championship'\n",
    "            \n",
    "        else:\n",
    "            urls = f'https://en.wikipedia.org/wiki/{year}_Copa_America'\n",
    "            \n",
    "        response = requests.get(urls)\n",
    "        content = response.text\n",
    "        \n",
    "        soup = BeautifulSoup(content, 'lxml')\n",
    "        matches = soup.find_all('div', class_=\"footballbox\")\n",
    "\n",
    "        home = []\n",
    "        score = []\n",
    "        away = []\n",
    "        \n",
    "        for match in matches:\n",
    "            home.append(match.find('th', class_=\"fhome\").get_text())\n",
    "            score.append(match.find('th', class_=\"fscore\").get_text())\n",
    "            away.append(match.find('th', class_=\"faway\").get_text())\n",
    "            \n",
    "        dict_America = {'home':home, \n",
    "                        'score':score,\n",
    "                        'away':away}\n",
    "\n",
    "        df_America = pd.DataFrame(dict_America)\n",
    "        df_America['year'] = year\n",
    "\n",
    "        return df_America\n",
    "    \n",
    "    def getTotalMatches(self, years):\n",
    "\n",
    "        TotalMatches = [self.get_matches(year) for year in years]\n",
    "        df_TotalMatches = pd.concat(TotalMatches, ignore_index=True)\n",
    "\n",
    "        df_conmebol = df_TotalMatches[df_TotalMatches['year'] != 2024]\n",
    "        df_fixture = df_TotalMatches[df_TotalMatches['year'] == 2024]\n",
    "\n",
    "        return df_conmebol, df_fixture\n",
    "    \n",
    "    def getMissingMatches(self, year):\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "        \n",
    "        url = f'https://en.wikipedia.org/wiki/{year}_Copa_America'\n",
    "        \n",
    "        driver.get(url) #Habilitamos el acceso al driver \n",
    "        \n",
    "        missing_matches = driver.find_elements(by='xpath', value='//tr[@style=\"font-size:90%\"]')\n",
    "\n",
    "        home = []\n",
    "        score = []\n",
    "        away = []\n",
    "\n",
    "        for match in missing_matches:\n",
    "            home.append(match.find_element(by='xpath', value='./td[1]').text)\n",
    "            score.append(match.find_element(by='xpath', value='./td[2]').text)\n",
    "            away.append(match.find_element(by='xpath', value='./td[3]').text)\n",
    "\n",
    "        dict_missing = {'home':home, \n",
    "                    'score':score,\n",
    "                    'away':away}\n",
    "\n",
    "        df_missing = pd.DataFrame(dict_missing)\n",
    "        df_missing['year'] = year\n",
    "        time.sleep(1) #Tiempo de espera para pasar de una página a la otra\n",
    "\n",
    "        return df_missing\n",
    "    \n",
    "    def getTotalMissingMatches(self, years):\n",
    "        missing_data = [self.getMissingMatches(year) for year in years]\n",
    "\n",
    "        # driver.quit() #Línea necesaria para que el driver deje de controlar la página web\n",
    "\n",
    "        df_missing_data = pd.concat(missing_data, ignore_index=True)\n",
    "\n",
    "        return df_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_America = [1916, 1917, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1929, 1935, 1937, 1939, 1941,\n",
    "                 1942, 1945, 1946, 1947, 1949, 1953, 1955, 1956, 1957, 1963, 1967, 1975, 1979, 1983, 1987, 1989,\n",
    "                 1991, 1993, 1995, 1997, 1999, 2001, 2004, 2007, 2011, 2015, 2016, 2019, 2021, 2024]\n",
    "\n",
    "missing_years = [2011, 2015]\n",
    "\n",
    "Partidos = DataCollector()\n",
    "tablas = Partidos.getTotalMatches(years_America)\n",
    "tablas_perdidas = Partidos.getTotalMissingMatches(missing_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablas[0].to_csv('Conmebol_Copa_America_initial_data.csv', index=False)\n",
    "tablas[1].to_csv('Programacion_Copa_America_2024.csv', index=False)\n",
    "tablas_perdidas.to_csv('Conmebol_Copa_America_missing_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "    '''\n",
    "    Clase encargada de limpiar los datos obtenidos usando WebScraping.\n",
    "    \n",
    "    Atributos:\n",
    "        - archivei con i = 1, 2, 3: Son los path de los archivos .csv con los datos necesarios\n",
    "        \n",
    "    Métodos:\n",
    "        - openData: Se encarga de convertir los archivos .csv en un DataFrame de pandas.\n",
    "\n",
    "        - cleanData: Se encarga de limpiar y transformar los datos para el uso adecuado.\n",
    "    '''\n",
    "    def __init__(self, archive1, archive2, archive3):\n",
    "        self.path1 = archive1\n",
    "        self.path2 = archive2\n",
    "        self.path3 = archive3\n",
    "    \n",
    "    def openData(self):\n",
    "        data1 = pd.read_csv(self.path1)\n",
    "        data2 = pd.read_csv(self.path2)\n",
    "        data3 = pd.read_csv(self.path3)\n",
    "        \n",
    "        return data1, data2, data3\n",
    "    \n",
    "    def cleanData(self, data, mode = 0):\n",
    "        if mode == 0: #Clean Fixture\n",
    "            data[0]['home'] = data[0].home.str.strip()\n",
    "            data[0]['away'] = data[0].away.str.strip()\n",
    "\n",
    "            for i in range(32):\n",
    "                data[0].loc[i, 'score'] = f'Match {i+1}'\n",
    "\n",
    "                data[0].loc[24, 'home'] = 'Winner Group A'\n",
    "                data[0].loc[24, 'away'] = 'Runner-up Group B'\n",
    "                data[0].loc[25, 'home'] = 'Winner Group B'\n",
    "                data[0].loc[25, 'away'] = 'Runner-up Group A'\n",
    "                data[0].loc[26, 'home'] = 'Winner Group D'\n",
    "                data[0].loc[26, 'away'] = 'Runner-up Group C'\n",
    "                data[0].loc[27, 'home'] = 'Winner Group C'\n",
    "                data[0].loc[27, 'away'] = 'Runner-up Group D'\n",
    "                \n",
    "                data[0].loc[28, 'home'] = 'Winner Match 25'\n",
    "                data[0].loc[28, 'away'] = 'Winner Match 26'\n",
    "                data[0].loc[29, 'home'] = 'Winner Match 27'\n",
    "                data[0].loc[29, 'away'] = 'Winner Match 28'\n",
    "\n",
    "                data[0].loc[30, 'home'] = 'Loser Match 29'\n",
    "                data[0].loc[30, 'away'] = 'Loser Match 30'\n",
    "\n",
    "                data[0].loc[31, 'home'] = 'Winner Match 29'\n",
    "                data[0].loc[31, 'away'] = 'Winner Match 30'\n",
    "\n",
    "\n",
    "\n",
    "            return data[0]\n",
    "        \n",
    "        elif mode == 1:\n",
    "            df_complete_data = pd.concat([data[1], data[2]], ignore_index=True)\n",
    "            df_complete_data.drop_duplicates(inplace=True)\n",
    "            df_complete_data.sort_values('year', inplace=True)\n",
    "\n",
    "            df_complete_data['score'] = df_complete_data['score'].str.strip()\n",
    "            df_complete_data['score'] = df_complete_data['score'].str.replace('[^\\d–]', '', regex=True)\n",
    "            \n",
    "            df_complete_data['home'] = df_complete_data.home.str.strip()\n",
    "            df_complete_data['away'] = df_complete_data.away.str.strip()\n",
    "\n",
    "            df_complete_data[['home_goals', 'away_goals']] = df_complete_data['score'].str.split('–', expand=True)\n",
    "            df_complete_data.drop('score', axis=1, inplace=True)\n",
    "\n",
    "            df_complete_data = df_complete_data.astype({'home_goals': int, 'away_goals':int, 'year':int})\n",
    "\n",
    "            df_home =  df_complete_data[['home', 'home_goals', 'away_goals']]\n",
    "            df_away =  df_complete_data[['away', 'home_goals', 'away_goals']]\n",
    "\n",
    "            #Renombrar Columnas\n",
    "            df_home = df_home.rename(columns={'home':'Team', 'home_goals':'Goals_Scored', 'away_goals':'Goals_Conceded'})\n",
    "            df_away = df_away.rename(columns={'away':'Team', 'home_goals':'Goals_Conceded', 'away_goals':'Goals_Scored'}) \n",
    "\n",
    "            return df_complete_data, df_home, df_away\n",
    "    \n",
    "    def teamStrength(self, df_h, df_a):\n",
    "        df_team_strength = pd.concat([df_h, df_a], ignore_index=True).groupby('Team').mean()\n",
    "        return df_team_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tablas = DataCleaner('Programacion_Copa_America_2024.csv',\n",
    "                    'Conmebol_Copa_America_initial_data.csv',\n",
    "                    'Conmebol_Copa_America_missing_data.csv')\n",
    "\n",
    "data = Tablas.openData()\n",
    "df_fixture = Tablas.cleanData(data)\n",
    "df_data = Tablas.cleanData(data, 1)\n",
    "df_complete_data = df_data[0]\n",
    "df_home = df_data[1]\n",
    "df_away = df_data[2]\n",
    "df_strength = Tablas.teamStrength(df_home, df_away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modeling:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def Rounds(self, df_f):\n",
    "        df_fixture_groups = df_f[:24].copy()\n",
    "        df_fixture_quarter = df_f[24:28].copy()\n",
    "        df_fixture_semi = df_f[28:30].copy()\n",
    "        df_fixture_final = df_f[30:].copy()\n",
    "\n",
    "        return df_fixture_groups, df_fixture_quarter, df_fixture_semi, df_fixture_final\n",
    "\n",
    "    def predict_points(self, df_s, home, away):\n",
    "        if home in df_s.index and away in df_s.index:\n",
    "            #goals_scored*goals_conceded\n",
    "            lamb_home = df_s.at[home, 'Goals_Scored'] * df_s.at[away, 'Goals_Conceded']\n",
    "            lamb_away = df_s.at[away, 'Goals_Scored'] * df_s.at[home, 'Goals_Conceded']\n",
    "            prob_home, prob_away, prob_draw = 0, 0, 0\n",
    "\n",
    "            for i in range(11): #Goles equipo local\n",
    "                for j in range(11): #Goles equipo visitante\n",
    "                    p = poisson.pmf(i, lamb_home) * poisson.pmf(j, lamb_away)\n",
    "                    if i == j:\n",
    "                        prob_draw += p\n",
    "                    elif i > j:\n",
    "                        prob_home += p\n",
    "                    else:\n",
    "                        prob_away += p\n",
    "        \n",
    "            points_home = 3 * prob_home + prob_draw\n",
    "            points_away = 3 * prob_away + prob_draw\n",
    "\n",
    "            return (points_home, points_away)\n",
    "        else:\n",
    "            return (0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fixture.to_csv('Programacion_Copa_America_2024.csv', index=False)\n",
    "df_complete_data.to_csv('Conmebol_Copa_America_complete_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('Conmebol_Copa_America_complete_data.csv')\n",
    "df_fixture = pd.read_csv('Programacion_Copa_America_2024.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
